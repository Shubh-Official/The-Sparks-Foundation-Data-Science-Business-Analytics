# -*- coding: utf-8 -*-
"""The_Sparks_Foundtion_Data_Science_&_Business_Analytics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bpE_3UGe5K4sfCLdRO5bTuTDXoEaus-0

# The Sprak Foundation #GRIPJUNE21

# Submitted by Shubh Patel

# GitHub Link : https://github.com/Shubh-Official/The-Sparks-Foundation-Data-Science-Business-Analytics

## Task-1 : Prediction using Supervised ML

* Predict the percentage of an student based on the no. of study hours.
* This is a simple linear regression task as it involves just 2 variables.
* You can use R, Python, SAS Enterprise Miner or any other tool
* Data can be found at http://bit.ly/w-data
* What will be predicted score if a student studies for 9.25 hrs/ day?

### Importing Packages
"""

import numpy as np
import pandas as pd
from matplotlib import pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error

"""### Exploring Data Set"""

data = pd.read_csv('student_scores - student_scores.csv')

print(data.shape)

data

"""### Data Visualization"""

plt.plot(data['Hours'], data['Scores'], 'ro')
plt.xlabel('Hours')
plt.ylabel('Scores')
plt.title('Percentage of a student based on the No. of Study Hours')
plt.show()

"""### Splitting Training and Testing Dataset"""

X = data['Hours'].values.reshape(data['Hours'].shape[0],1)
y = data['Scores'].values.reshape(data['Scores'].shape[0],1)

print(X.shape)
print(y.shape)

X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

"""### Training a Model using Training Dataset"""

model = LinearRegression()
model.fit(X_train, y_train)

print('y = mX + c')
print('h(X) = Theta1 * X + Theta0')
print('--------------------------')
print('Theta1 (m) =', model.coef_)
print('Theta0 (c) =', model.intercept_)

Theta1 = model.coef_
Theta0 = model.intercept_

h_x = Theta1 * X + Theta0

plt.plot(X, y, 'ro')
plt.plot(X, h_x, 'g-')
plt.xlabel('Hours')
plt.ylabel('Scores')
plt.title('Percentage of a student based on the No. of Study Hours with Model Reference Line')
plt.legend(['Original Scores', 'Model Prediction Reference Line'], loc='best')
plt.show()

"""### Making Prediction on Testing Dataset"""

y_predicted = model.predict(X_test)
model.score(X_test, y_test)

df = pd.DataFrame({'Test Hours Value': X_test[:,0], 'Actual Score': y_test[:,0], 'Predicted Score': y_predicted[:,0]})
df

"""### Making Prediction on given Hours"""

given_hours = [[9.25]]
predicted_scores = model.predict(given_hours)

print('For the given number of Hours :', given_hours[0][0])
print('Predicted Score :', predicted_scores[0][0])

"""### Finding Mean Absolute Error and Mean Square Error"""

print('Mean Absolute Error :', mean_absolute_error(y_test, y_predicted))
print('Mean Square Error :', mean_squared_error(y_test, y_predicted))

"""## Task-2 : Prediction using Unsupervised ML

* From the given ‘Iris’ dataset, predict the optimum number of clusters and represent it visually.
* Use R or Python or perform this task
* Dataset : https://bit.ly/3kXTdox

### Importing Packages
"""

import numpy as np
import pandas as pd
from matplotlib import pyplot as plt

from sklearn.cluster import KMeans

"""### Exploring Data Set"""

data = pd.read_csv('Iris.csv')

print(data.shape)

data

"""### Splitting into Input and Target Data"""

X = data.iloc[:, [1, 2, 3, 4]].values
X

y = data.iloc[:, 5].values
y

"""### Applying K-Means Clustering and Printing Centroids"""

kmeans = KMeans(n_clusters = 3, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 5)
y_predicted = kmeans.fit_predict(X)

kmeans.cluster_centers_

"""### Visual Representation of Clusters"""

fig = plt.figure(figsize=(25,20))

plt.scatter(X[y_predicted == 0, 0], X[y_predicted == 0, 1], s = 100, c = 'red', label = 'Iris-setosa')
plt.scatter(X[y_predicted == 1, 0], X[y_predicted == 1, 1], s = 100, c = 'blue', label = 'Iris-versicolour')
plt.scatter(X[y_predicted == 2, 0], X[y_predicted == 2, 1], s = 100, c = 'green', label = 'Iris-virginica')

plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:,1], s = 100, c = 'yellow', label = 'Centroids')

plt.legend()
plt.show()

"""## Task-6 : Prediction using Decision Tree Algorithm

* Create the Decision Tree classifier and visualize it graphically.
* The purpose is if we feed any new data to this classifier, it would be able to predict the right class accordingly.
* Dataset : https://bit.ly/3kXTdox

### Installing Necessary Packages
"""

# Install required libraries
!pip install pydotplus
!apt-get install graphviz -y

# Install required libraries
!pip install dtreeviz
!apt-get install dtreeviz -y

"""### Importing Packages"""

import numpy as np
import pandas as pd
from matplotlib import pyplot as plt

from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree, export_graphviz

import graphviz

from dtreeviz.trees import dtreeviz
from IPython.core.display import display, HTML

"""### Exploring Data Set"""

data = pd.read_csv('Iris.csv')

print(data.shape)

data

"""### Splitting into Input and Target Data"""

X = data.iloc[:, [1, 2, 3, 4]].values
X

y = data.iloc[:, 5].values
y = np.where(y == 'Iris-setosa', 0, y)
y = np.where(y == 'Iris-versicolor', 1, y)
y = np.where(y == 'Iris-virginica', 2, y)
y = y.astype('int')
y

"""### Applying Decision Tree Classifier"""

dtc = DecisionTreeClassifier(random_state = 3)
dtc.fit(X, y)

"""### Textal Representation of Decision Tree"""

text_representation_dtc = export_text(dtc)
print(text_representation_dtc)

"""### Saving Textual Representation of Decision Tree as .log File"""

with open("decistion_tree.log", "w") as fout:
    fout.write(text_representation_dtc)

print("***** decisition_tree.log ***** Successfully Created")

"""### Graphical Representation of Decision Tree using plot_tree function"""

fig = plt.figure(figsize=(25,20))

_ = plot_tree(dtc, feature_names=data.columns[1:5], class_names=data.iloc[:,5].unique(), filled=True, rounded=True)

"""### Saving Graphical Representation of Decision Tree in .png Format"""

fig.savefig("decistion_tree.png")

print("***** decisition_tree.log ***** Saved Successfully")

"""### Graphical Representation of Decision Tree using Graphviz library"""

dtc_graph = export_graphviz(dtc, out_file=None, feature_names=data.columns[1:5], class_names=data.iloc[:,5].unique(), filled=True, rounded=True)

dtc_png = graphviz.Source(dtc_graph, format="png")
dtc_png

"""### Saving Graphical Representation of Decision Tree in .png Format"""

dtc_png.render("decision_tree_graphivz")

"""### Graphical Representation of Desicion Tree using dtreeviz Package"""

viz = dtreeviz(
        dtc,
        X,
        y,
        target_name='Species',
        feature_names=data.columns[1:5], 
        class_names=["Iris-setosa", "Iris-versicolor", "Iris-virginica"],
        fancy=True
    )

display(HTML(viz.svg()))

"""References for **dtreeviz** Library / Packages

https://mljar.com/blog/visualize-decision-tree/

https://stackoverflow.com/questions/56683489/use-dtreeviz-to-visualize-decision-tree
"""